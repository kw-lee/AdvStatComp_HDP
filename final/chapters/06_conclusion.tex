\section{Conclusion}

So far, our group comprehended and emulated the results of approximation of high-dimensional multivariate normal probabilities which comprises three concepts: hierarchical representation, $d$-dimensional conditioning, and block reordering. For computer simulation, our group used Julia. In terms of computing, our group reproduced all the procedures mentioned in \citet{cao2019hierarchical} such as \texttt{CMVN}, \texttt{RCMVN}, \texttt{HCMVN}, \texttt{HRCMVN}, and block reordering. The numbers including running time, error rate, etc were not exactly in line with \citet{cao2019hierarchical}. Even though we followed the streamline of the published pseudocodes of each methods, it might be the case that the difference of computing environment of our group and the authors produce the difference. By using distinct programming language, possessing different computers with unequal quality of CPUs, generating rule of random numbers (e.g. seed number), etc.

In \citet{cao2019hierarchical}, the experiments were done by setting covariance structure by 2D or 1D exponential spatial model along with Morton ordering, which is feasible to take advantage of hierarchical decomposition for covariance matrix. Although \citet{cao2019hierarchical} suggested that in the case of completely random, non-hierarchical method might show better performance in terms of computing time, it seems rational that the hierarchical decomposition method is effective approach for the case of smooth covariance function. The procedure of $d$-dimensional conditioning and block reordering scheme improved accuracy of estimated value under the exponential covariance structure, with negligible amount of computing time and cost. The integrated value is computed by multiplyng truncated expectation values, computed based on the principle of Quasi-Monte Carlo simulation. Hence, it remains further topic of research to delve into the methodology of estimating the truncated expectations of multivariate normal random variables. Furthermore, considering that our approximation method dealt with the case of covariance structure that $m$ divides $n$. This means that $m \times m$ block matrices can fit the diagonal line of the original covariance matrix. Therefore, it might be worth studying deeply about the issue when $m$ does not divide $n$, so there exist remnants on diagonal locations.